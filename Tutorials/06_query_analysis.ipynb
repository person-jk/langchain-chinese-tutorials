{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 搭建查询分析系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本页将介绍如何在基本的端到端示例中使用查询分析。\n",
    "\n",
    "这将介绍创建一个简单的搜索引擎，显示将原始用户问题传递给该搜索时发生的失败模式，然后介绍查询分析如何帮助解决该问题。\n",
    "\n",
    "有许多不同的查询分析技术，此端到端示例不会显示所有这些技术。\n",
    "\n",
    "在本例中，我们将对LangChain YouTube视频进行检索。 （本来想用B站的，结果方法确实支持得有问题）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装依赖项\n",
    "# %pip install -qU langchain langchain-community langchain-openai youtube-transcript-api pytube langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置环境变量\n",
    "# 在此示例中，我们将使用 OpenAI\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm =  ChatOpenAI(model=\"gpt-3.5-turbo\", base_url=\"https://api.gpts.vin/v1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载文档\n",
    "\n",
    "我们可以用 来加载一些LangChain视频的文字记录：BiliBiliLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://www.youtube.com/watch?v=HAn9vnJy6S4\",\n",
    "    \"https://www.youtube.com/watch?v=dA1cHGACXCo\",\n",
    "    \"https://www.youtube.com/watch?v=ZcEMLz27sL4\",\n",
    "    \"https://www.youtube.com/watch?v=hvAPnpSfSGo\",\n",
    "    \"https://www.youtube.com/watch?v=EhlPDL4QrWY\",\n",
    "    \"https://www.youtube.com/watch?v=mmBo8nlu2j0\",\n",
    "    \"https://www.youtube.com/watch?v=rQdibOsL1ps\",\n",
    "    \"https://www.youtube.com/watch?v=28lC4fqukoc\",\n",
    "    \"https://www.youtube.com/watch?v=es-9MgxB-uc\",\n",
    "    \"https://www.youtube.com/watch?v=wLRHwKuKvOE\",\n",
    "    \"https://www.youtube.com/watch?v=ObIltMaRJvY\",\n",
    "    \"https://www.youtube.com/watch?v=DjuXACWYkkU\",\n",
    "    \"https://www.youtube.com/watch?v=o7C9ld6Ln-M\",\n",
    "]\n",
    "docs = []\n",
    "for url in urls:\n",
    "    docs.extend(YoutubeLoader.from_youtube_url(url, add_video_info=True).load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Add some additional metadata: what year the video was published\n",
    "for doc in docs:\n",
    "    doc.metadata[\"publish_year\"] = int(\n",
    "        datetime.datetime.strptime(\n",
    "            doc.metadata[\"publish_date\"], \"%Y-%m-%d %H:%M:%S\"\n",
    "        ).strftime(\"%Y\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OpenGPTs',\n",
       " 'Building a web RAG chatbot: using LangChain, Exa (prev. Metaphor), LangSmith, and Hosted Langserve',\n",
       " 'Streaming Events: Introducing a new `stream_events` method',\n",
       " 'LangGraph: Multi-Agent Workflows',\n",
       " 'Build and Deploy a RAG app with Pinecone Serverless',\n",
       " 'Auto-Prompt Builder (with Hosted LangServe)',\n",
       " 'Build a Full Stack RAG App With TypeScript',\n",
       " 'Getting Started with Multi-Modal LLMs',\n",
       " 'SQL Research Assistant',\n",
       " 'Skeleton-of-Thought: Building a New Template from Scratch',\n",
       " 'Benchmarking RAG over LangChain Docs',\n",
       " 'Building a Research Assistant from Scratch',\n",
       " 'LangServe and LangChain Templates Webinar']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以下是我们加载的视频的标题：\n",
    "[doc.metadata[\"title\"] for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是与每个视频关联的元数据。我们可以看到，每个文档还有一个标题、浏览次数、发布日期和长度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'HAn9vnJy6S4',\n",
       " 'title': 'OpenGPTs',\n",
       " 'description': 'Unknown',\n",
       " 'view_count': 8717,\n",
       " 'thumbnail_url': 'https://i.ytimg.com/vi/HAn9vnJy6S4/hq720.jpg',\n",
       " 'publish_date': '2024-01-31 00:00:00',\n",
       " 'length': 1530,\n",
       " 'author': 'LangChain',\n",
       " 'publish_year': 2024}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是文档内容的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello today I want to talk about open gpts open gpts is a project that we built here at linkchain uh that replicates the GPT store in a few ways so it creates uh end user-facing friendly interface to create different Bots and these Bots can have access to different tools and they can uh be given files to retrieve things over and basically it's a way to create a variety of bots and expose the configuration of these Bots to end users it's all open source um it can be used with open AI it can be us\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 索引文档\n",
    "每当我们执行检索时，我们都需要创建一个可以查询的文档索引。\n",
    "\n",
    "我们将使用向量存储来索引我们的文档，我们将首先对它们进行分块，以使我们的检索更加简洁和精确："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = getpass.getpass() # 向量模型也是用阿里\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
    "chunked_docs = text_splitter.split_documents(docs)\n",
    "embeddings = DashScopeEmbeddings()\n",
    "vectorstore = Chroma.from_documents(\n",
    "    chunked_docs,\n",
    "    embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 不带查询分析的检索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以直接对用户问题进行相似性搜索，以查找与该问题相关的块：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangServe and LangChain Templates Webinar\n",
      "to have kind of like a common interface for everything and so uh what that means is that we probably won't have specialized endpoints at the moment for different things um because they'll all we'll handle them in like a generic way but I do think there's a good chance that we start having like a collection of templates that are themselves retrievers or something like that um so I think like we have some Advanced rag methods in there that I think actually some of them probably are just like retri\n"
     ]
    }
   ],
   "source": [
    "search_results = vectorstore.similarity_search(\"我该怎么去构建一个RAG代理？\")\n",
    "print(search_results[0].metadata[\"title\"])\n",
    "print(search_results[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这很有效！我们的第一个结果与这个问题非常相关。\n",
    "\n",
    "如果我们想搜索特定时间段的结果，该怎么办？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Deploy a RAG app with Pinecone Serverless\n",
      "2024-01-16 00:00:00\n",
      "hi this is Lance from the Lang chain team and today we're going to be building and deploying a rag app using pine con serval list from scratch so we're going to kind of walk through all the code required to do this and I'll use these slides as kind of a guide to kind of lay the the ground work um so first what is rag so under capoy has this pretty nice visualization that shows LMS as a kernel of a new kind of operating system and of course one of the core components of our operating system is th\n"
     ]
    }
   ],
   "source": [
    "search_results = vectorstore.similarity_search(\"2023 年发布的 RAG 视频\")\n",
    "print(search_results[0].metadata[\"title\"])\n",
    "print(search_results[0].metadata[\"publish_date\"])\n",
    "print(search_results[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的第一个结果是 2024 年的（尽管我们要求提供 2023 年的视频），与输入不是很相关。\n",
    "\n",
    "由于我们只是针对文档内容进行搜索，因此无法根据任何文档属性筛选结果。\n",
    "\n",
    "这只是可能出现的一种故障模式。现在让我们来看看查询分析的基本形式是如何解决它的！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查询分析\n",
    "我们可以使用查询分析来改进检索结果。这将涉及定义包含一些日期筛选器的查询架构，并使用函数调用模型将用户问题转换为结构化查询。\n",
    "\n",
    "#### 查询架构\n",
    "在本例中，我们将为发布日期提供显式的 min 和 max 属性，以便对其进行筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Search(BaseModel):\n",
    "    \"\"\"搜索有关软件库的教程视频数据库.\"\"\"\n",
    "\n",
    "    query: str = Field(\n",
    "        ...,\n",
    "        description=\"应用于视频文字记录的相似性搜索查询.\",\n",
    "    )\n",
    "    publish_year: Optional[int] = Field(None, description=\"视频发布年份\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查询生成\n",
    "为了将用户问题转换为结构化查询，我们将使用 OpenAI 的工具调用 API。\n",
    "\n",
    "具体来说，我们将使用新的 ChatModel.with_structured_output（） 构造函数来处理将架构传递给模型并分析输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] =getpass.getpass()\n",
    "\n",
    "system = \"\"\"您是将用户问题转换为数据库查询的专家。\n",
    "您可以访问有关用于构建 LLM 支持的应用程序的软件库的教程视频数据库。\n",
    "给定一个问题，返回一个数据库查询列表，这些查询经过优化，可以检索最相关的结果。\n",
    "\n",
    "如果有您不熟悉的首字母缩略词或单词，请不要尝试改写它们。\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "llm =  ChatOpenAI(model=\"gpt-3.5-turbo\", base_url=\"https://api.gpts.vin/v1\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(Search)\n",
    "query_analyzer = {\"question\": RunnablePassthrough()} | prompt | structured_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们看看我们的分析器为我们之前搜索的问题生成了哪些查询："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Search(query='RAG代理构建指南', publish_year=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"我该怎么去构建一个RAG代理\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Search(query='RAG', publish_year=2023)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"videos on RAG published in 2023\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用查询分析进行检索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的查询分析看起来相当不错;现在，让我们尝试使用生成的查询来实际执行检索。\n",
    "\n",
    "注意：在我们的示例中，我们指定了 .这将强制 LLM 调用一个 - 并且只有一个 - 工具，这意味着我们将始终有一个优化的查询来查找。\n",
    "\n",
    "请注意，情况并非总是如此 - 请参阅其他指南，了解如何处理未返回或返回多个优化查询的情况。`tool_choice=\"Search\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(search: Search) -> List[Document]:\n",
    "    if search.publish_year is not None:\n",
    "        # This is syntax specific to Chroma,\n",
    "        # the vector database we are using.\n",
    "        _filter = {\"publish_year\": {\"$eq\": search.publish_year}}\n",
    "    else:\n",
    "        _filter = None\n",
    "    return vectorstore.similarity_search(search.query, filter=_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = query_analyzer | retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在可以在之前有问题的输入上运行这个链，并看到它只产生当年的结果！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = retrieval_chain.invoke(\"2023 年发布的 RAG 教程\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Getting Started with Multi-Modal LLMs', '2023-12-20 00:00:00'),\n",
       " ('Getting Started with Multi-Modal LLMs', '2023-12-20 00:00:00'),\n",
       " ('Getting Started with Multi-Modal LLMs', '2023-12-20 00:00:00'),\n",
       " ('Getting Started with Multi-Modal LLMs', '2023-12-20 00:00:00')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(doc.metadata[\"title\"], doc.metadata[\"publish_date\"]) for doc in results]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
